\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {1}{\ignorespaces The sigmoid function: $\sigma : \theta ^T\boldsymbol {x}\in \ensuremath {\PazoBB {R}}\rightarrow [0,1]$\relax }}{6}{figure.caption.2}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2}{\ignorespaces Abstract representation of a three-layer neural network architecture, where each circle represents a neuron. $\theta $ controls the flow of information between activation layers.\relax }}{10}{figure.caption.3}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {3}{\ignorespaces Abstraction of an RNN over a time series. The activation of the neurons in the hidden layer is a function of the input from the previous layer and its own output from the previous computation. \relax }}{12}{figure.caption.4}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4}{\ignorespaces The chained structure of an LSTM memory cell. Each cell contains multiple network layers, where the RNN presented previously has only one (the sigmoid layer). Diagram borrowed from \citet {colah2015lstms}.\relax }}{14}{figure.caption.5}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {5}{\ignorespaces chord-scale duality.\relax }}{16}{figure.caption.6}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {6}{\ignorespaces The opening of the chorale \textit {Nun lob' mein' Seel', den Herren} \relax }}{20}{figure.caption.7}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {7}{\ignorespaces First phrase of \textit {Warum betrübst du dich, mein Herz} \relax }}{21}{figure.caption.8}
