%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for hzabriskie at 2015-12-03 14:53:24 -0500 


%% Saved with string encoding Unicode (UTF-8) 



@misc{johnson2015compose,
	Author = {Daniel Johnson},
	Date-Added = {2015-12-03 19:51:57 +0000},
	Date-Modified = {2015-12-03 19:53:23 +0000},
	Day = {3},
	Howpublished = {Blog},
	Keywords = {RNN, machine learning, neural networks},
	Month = {August},
	Title = {Composing Music With Recurrent Neural Networks},
	Url = {http://www.hexahedria.com/2015/08/03/composing-music-with-recurrent-neural-networks/},
	Year = {2015}}

@article{allan2005harmonising,
	Author = {Allan, Moray and Williams, Christopher KI},
	Date-Added = {2015-12-03 07:20:57 +0000},
	Date-Modified = {2015-12-03 07:21:18 +0000},
	Journaltitle = {Advances in neural information processing systems},
	Keywords = {chorales, machine learning, harmonization},
	Pages = {25--32},
	Title = {Harmonising chorales by probabilistic inference},
	Volume = {17},
	Year = {2005},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QVy4uLy4uL2FydGljbGVzL0FsbGFuIGFuZCBXaWxsaWFtcyAtIEhhcm1vbmlzaW5nIENob3JhbGVzIGJ5IFByb2JhYmlsaXN0aWMgSW5mZXJlbmNlLnBkZtIXCxgZV05TLmRhdGFPEQJqAAAAAAJqAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADNZNKaSCsAAANNd8MfQWxsYW4gYW5kIFdpbGxpYW1zICMzQTREQTE5LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA6TaGdKCTjgAAAAAAAAAAAACAAIAAAkgAAAAAAAAAAAAAAAAAAAACGFydGljbGVzABAACAAAzWUK2gAAABEACAAA0oKUiAAAAAEAFANNd8MCZLCaAAXxYwAFxGkAAhDpAAIAWk1hY2ludG9zaCBIRDpVc2VyczoAaHphYnJpc2tpZToARHJvcGJveDoAVGhlc2lzOgBhcnRpY2xlczoAQWxsYW4gYW5kIFdpbGxpYW1zICMzQTREQTE5LnBkZgAOAJIASABBAGwAbABhAG4AIABhAG4AZAAgAFcAaQBsAGwAaQBhAG0AcwAgAC0AIABIAGEAcgBtAG8AbgBpAHMAaQBuAGcAIABDAGgAbwByAGEAbABlAHMAIABiAHkAIABQAHIAbwBiAGEAYgBpAGwAaQBzAHQAaQBjACAASQBuAGYAZQByAGUAbgBjAGUALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAHFVc2Vycy9oemFicmlza2llL0Ryb3Bib3gvVGhlc2lzL2FydGljbGVzL0FsbGFuIGFuZCBXaWxsaWFtcyAtIEhhcm1vbmlzaW5nIENob3JhbGVzIGJ5IFByb2JhYmlsaXN0aWMgSW5mZXJlbmNlLnBkZgAAEwABLwAAFQACABH//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDoAO0A9QNjA2UDagN1A34DjAOQA5cDoAOlA7IDtQPHA8oDzwAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAPR}}

@article{greff2015lstm,
	Abstract = {Several variants of the Long Short-Term Memory (LSTM) architecture for recurrent neural networks have been proposed since its inception in 1995. In recent years, these networks have become the state-of-the-art models for a variety of machine learning problems. This has led to a renewed interest in understanding the role and utility of various computational components of typical LSTM variants. In this paper, we present the first large-scale analysis of eight LSTM variants on three representative tasks: speech recognition, handwriting recognition, and polyphonic music modeling. The hyperparameters of all LSTM variants for each task were optimized separately using random search and their importance was assessed using the powerful fANOVA framework. In total, we summarize the results of 5400 experimental runs (about 15 years of CPU time), which makes our study the largest of its kind on LSTM networks. Our results show that none of the variants can improve upon the standard LSTM architecture significantly, and demonstrate the forget gate and the output activation function to be its most critical components. We further observe that the studied hyperparameters are virtually independent and derive guidelines for their efficient adjustment.},
	Author = {Klaus Greff and Rupesh Kumar Srivastava and Jan Koutnik and Bas R. Steunebrink and Jurgen Schmidhuber},
	Date-Added = {2015-12-03 07:17:15 +0000},
	Date-Modified = {2015-12-03 07:20:01 +0000},
	Journaltitle = {arXiv preprint arXiv:1503.04069},
	Keywords = {LSTM, neural networks, chorales},
	Title = {LSTM: A Search Space Odyssey},
	Url = {http://adsabs.harvard.edu/abs/2015arXiv150304069G},
	Urlday = {3},
	Urlmonth = {December},
	Urlyear = {2015},
	Year = {2015}}

@incollection{goel2014polyphonic,
	Author = {Goel, Kratarth and Vohra, Raunaq and Sahoo, JK},
	Booktitle = {Artificial Neural Networks and Machine Learning--ICANN 2014},
	Date-Added = {2015-12-03 07:15:01 +0000},
	Date-Modified = {2015-12-03 07:15:28 +0000},
	Keywords = {machine learning, chorales, neural networks, LSTM},
	Pages = {217--224},
	Publisher = {Springer},
	Title = {Polyphonic Music Generation by Modeling Temporal Dependencies Using a RNN-DBN},
	Year = {2014}}

@article{mozer1994neural,
	Author = {Mozer, Michael C},
	Date-Added = {2015-12-03 07:10:32 +0000},
	Date-Modified = {2015-12-03 07:11:19 +0000},
	Journaltitle = {Connection Science},
	Keywords = {harmonization, chorales, neural networks},
	Number = {2-3},
	Pages = {247--280},
	Publisher = {Taylor \& Francis},
	Title = {Neural network music composition by prediction: Exploring the benefits of psychoacoustic constraints and multi-scale processing},
	Volume = {6},
	Year = {1994}}

@article{liu2014Bach,
	Abstract = {We propose a framework for computer music composition that uses resilient propagation (RProp) and long short term memory (LSTM) recurrent neural network. In this paper, we show that LSTM network learns the structure and characteristics of music pieces properly by demonstrating its ability to recreate music. We also show that predicting existing music using RProp outperforms Back propagation through time (BPTT).},
	Author = {I-Ting Liu and Bhiksha Ramakrishnan},
	Date-Added = {2015-12-03 06:27:01 +0000},
	Date-Modified = {2015-12-03 06:28:15 +0000},
	Eprint = {1412.3191},
	Keywords = {harmonization, LSTM, neural networks},
	Month = {12},
	Title = {Bach in 2014: Music Composition with Recurrent Neural Network},
	Url = {http://arxiv.org/abs/1412.3191},
	Year = {2014},
	Bdsk-Url-1 = {http://arxiv.org/abs/1412.3191}}

@article{franklin2006jazz,
	Author = {Franklin, Judy A},
	Date-Added = {2015-12-03 04:53:40 +0000},
	Date-Modified = {2015-12-03 07:11:44 +0000},
	Journaltitle = {International Journal on Artificial Intelligence Tools},
	Keywords = {jazz, neural networks, RNN},
	Number = {04},
	Pages = {623--650},
	Publisher = {World Scientific},
	Title = {Jazz melody generation using recurrent networks and reinforcement learning},
	Volume = {15},
	Year = {2006}}

@book{laitz2008,
	Author = {Laitz, Steven Geoffrey},
	Date-Added = {2015-11-30 20:00:21 +0000},
	Date-Modified = {2015-11-30 20:02:41 +0000},
	Edition = {3rd},
	Keywords = {musical structure, harmonization, music theory},
	Location = {New York},
	Publisher = {Oxford University Press, USA},
	Title = {The complete musician: An integrated approach to tonal theory, analysis, and listening},
	Volume = {1},
	Year = {2012}}

@article{hochreiter1997long,
	Author = {Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
	Date-Added = {2015-11-29 02:49:03 +0000},
	Date-Modified = {2015-11-29 02:51:01 +0000},
	Editor = {MIT Press},
	Journaltitle = {Neural Computation},
	Keywords = {LSTM, neural networks},
	Number = {8},
	Pages = {1735--1780},
	Title = {Long short-term memory},
	Url = {http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf},
	Volume = {9},
	Year = {1997},
	Bdsk-Url-1 = {http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf}}

@article{leaverchorale,
	Author = {Robin A. Leaver and Robert L. Marshall},
	Date-Added = {2015-11-27 16:19:19 +0000},
	Date-Modified = {2015-11-27 20:10:22 +0000},
	Journaltitle = {Grove Music Online. Oxford Music Online},
	Keywords = {musical structure, chorales},
	Title = {Chorale},
	Url = {http://www.oxfordmusiconline.com.ezp-prod1.hul.harvard.edu/subscriber/article/grove/music/05652},
	Urlday = {27},
	Urlmonth = {November},
	Urlyear = {2015},
	Year = {2015},
	Bdsk-Url-1 = {http://www.oxfordmusiconline.com.ezp-prod1.hul.harvard.edu/subscriber/article/grove/music/05652}}

@techreport{goldberg2015nnlp,
	Author = {Yoav Goldberg},
	Date-Added = {2015-11-27 05:23:31 +0000},
	Date-Modified = {2015-11-27 05:25:35 +0000},
	Institution = {Bar-Ilan University},
	Keywords = {machine learning, neural networks, RNN, LSTM},
	Title = {A Primer on Neural Network Models for Natural Language Processing},
	Year = {2015},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOC4uLy4uL2FydGljbGVzL0dvbGJlcmcgTmV1cmFsIE5ldHdvcmsgUHJpbWVyIChkcmFmdCkucGRm0hcLGBlXTlMuZGF0YU8RAgwAAAAAAgwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM1k0ppIKwAAA013wx9Hb2xiZXJnIE5ldXJhbCBOZXR3IzNBMUE5NjEucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADoalh0n1ToAAAAAAAAAAAAAIAAgAACSAAAAAAAAAAAAAAAAAAAAAIYXJ0aWNsZXMAEAAIAADNZQraAAAAEQAIAADSfZnwAAAAAQAUA013wwJksJoABfFjAAXEaQACEOkAAgBaTWFjaW50b3NoIEhEOlVzZXJzOgBoemFicmlza2llOgBEcm9wYm94OgBUaGVzaXM6AGFydGljbGVzOgBHb2xiZXJnIE5ldXJhbCBOZXR3IzNBMUE5NjEucGRmAA4AVAApAEcAbwBsAGIAZQByAGcAIABOAGUAdQByAGEAbAAgAE4AZQB0AHcAbwByAGsAIABQAHIAaQBtAGUAcgAgACgAZAByAGEAZgB0ACkALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAFJVc2Vycy9oemFicmlza2llL0Ryb3Bib3gvVGhlc2lzL2FydGljbGVzL0dvbGJlcmcgTmV1cmFsIE5ldHdvcmsgUHJpbWVyIChkcmFmdCkucGRmABMAAS8AABUAAgAR//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AyQDOANYC5gLoAu0C+AMBAw8DEwMaAyMDKAM1AzgDSgNNA1IAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADVA==}}

@book{murphy2012machine,
	Address = {Cambridge, Massachusetts},
	Author = {Murphy, Kevin P},
	Date-Added = {2015-11-27 05:09:37 +0000},
	Date-Modified = {2015-11-27 05:16:20 +0000},
	Keywords = {machine learning},
	Publisher = {MIT press},
	Title = {Machine learning: a probabilistic perspective},
	Year = {2012}}

@article{cuthbertmusic21,
	Author = {Cuthbert, Michael Scott and Ariza, Christopher},
	Date-Added = {2015-11-27 04:55:56 +0000},
	Date-Modified = {2015-11-27 04:57:36 +0000},
	Journal = {International Society for Music Information Retrieval},
	Keywords = {music21},
	Month = {August},
	Pages = {637-642},
	Title = {music21: A toolkit for computer-aided musicology and symbolic music data},
	Year = {2010},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QKS4uLy4uL2FydGljbGVzL0N1dGhiZXJ0IE11c2ljMjEgUGFwZXIucGRm0hcLGBlXTlMuZGF0YU8RAdwAAAAAAdwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM1k0ppIKwAAA013wxpDdXRoYmVydCBNdXNpYzIxIFBhcGVyLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADoZYy0n1HWgAAAAAAAAAAAAIAAgAACSAAAAAAAAAAAAAAAAAAAAAIYXJ0aWNsZXMAEAAIAADNZQraAAAAEQAIAADSfY2qAAAAAQAUA013wwJksJoABfFjAAXEaQACEOkAAgBVTWFjaW50b3NoIEhEOlVzZXJzOgBoemFicmlza2llOgBEcm9wYm94OgBUaGVzaXM6AGFydGljbGVzOgBDdXRoYmVydCBNdXNpYzIxIFBhcGVyLnBkZgAADgA2ABoAQwB1AHQAaABiAGUAcgB0ACAATQB1AHMAaQBjADIAMQAgAFAAYQBwAGUAcgAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAQ1VzZXJzL2h6YWJyaXNraWUvRHJvcGJveC9UaGVzaXMvYXJ0aWNsZXMvQ3V0aGJlcnQgTXVzaWMyMSBQYXBlci5wZGYAABMAAS8AABUAAgAR//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AugC/AMcCpwKpAq4CuQLCAtAC1ALbAuQC6QL2AvkDCwMOAxMAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADFQ==}}

@misc{colah2015lstms,
	Annote = {In his recent blog post, Chris Olah describe a special model of recurrent neural networks known as LSTM Networks, or Long Short-Term Memory Networks. He describes the significant advances that recurrent neural networks made over "vanilla" (or non-recurrent) neural networks by allowing information to persist within the model. Theoretically, RNNs should be able to draw on information from previous decisions to make its current one, but in practice they have only proven effective when the distance between the relevant past information and the time frame in which it is required is small. LSTMs solved this problem by altering the structure of the network's hidden activation layers to create a pipeline of persisting information and a series of control gates for allowing new information to enter the pipeline.

This blog post is aimed at machine learning researching with a general understanding of neural networks and are seeking a more visual and approachable introduction to LSTMs. While a young author, Chris is a highly accomplished researcher and engineer in the field, and his explanations are concise, descriptive, and well-researched, citing several relevant papers. },
	Author = {Christopher Olah},
	Date = {August 27, 2015},
	Date-Added = {2015-09-30 04:52:04 +0000},
	Date-Modified = {2015-12-03 17:19:57 +0000},
	Howpublished = {Blog},
	Keywords = {LSTM, neural networks},
	Rating = {5},
	Title = {Understanding LSTM Networks},
	Url = {http://colah.github.io/posts/2015-08-Understanding-LSTMs/},
	Year = {2015},
	Bdsk-Url-1 = {http://colah.github.io/posts/2015-08-Understanding-LSTMs/}}

@article{madsen2002,
	Annote = {This report represents a fairly standard approach to the task of automatic harmonization of Bach chorales. Given the melody of a chorale, the authors developed a neural network to provide harmonic support for each note in the melody, which has been abstracted to series a quarter notes for the sake of evenly distributed time frames. Input features include past and previous elements of the melody, previously determined harmonies, and contextual elements of the current soprano note, such as beat strength. After experimenting with several different data representations for the feature vectors, they discovered a relatively effective solution when they represented the output vector as a range of MIDI notes from which the alto, tenor, and bass voices were selected.

This paper is also somewhat dated and doesn't provide an adequate explanation of their neural network construction. However, their method is preprocessing (that is, abstracting chorales into quarter-note time frames) is intruiging and likely to be used in my initial experiments with RNNs.  },
	Author = {Soren Tjagvad Madsen and Martin Elmer Jorgensen},
	Date-Added = {2015-09-29 18:33:45 +0000},
	Date-Modified = {2015-12-03 06:30:33 +0000},
	Keywords = {chorales, neural networks},
	Month = {August},
	Pages = {31},
	School = {University of Aarhus},
	Title = {Harmonisation of Bach chorales: KBS project report},
	Year = {2002},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOC4uLy4uL2FydGljbGVzL0tCUyBSZXBvcnQgQmFjaCBDaG9yYWxlIEhhcm1vbml6YXRpb24ucGRm0hcLGBlXTlMuZGF0YU8RAgwAAAAAAgwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM1k0ppIKwAAA013wx9LQlMgUmVwb3J0IEJhY2ggQ2hvIzM1MUI0MDUucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADUbQF0jIJdgAAAAAAAAAAAAIAAgAACSAAAAAAAAAAAAAAAAAAAAAIYXJ0aWNsZXMAEAAIAADNZQraAAAAEQAIAADSMkG2AAAAAQAUA013wwJksJoABfFjAAXEaQACEOkAAgBaTWFjaW50b3NoIEhEOlVzZXJzOgBoemFicmlza2llOgBEcm9wYm94OgBUaGVzaXM6AGFydGljbGVzOgBLQlMgUmVwb3J0IEJhY2ggQ2hvIzM1MUI0MDUucGRmAA4AVAApAEsAQgBTACAAUgBlAHAAbwByAHQAIABCAGEAYwBoACAAQwBoAG8AcgBhAGwAZQAgAEgAYQByAG0AbwBuAGkAegBhAHQAaQBvAG4ALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAFJVc2Vycy9oemFicmlza2llL0Ryb3Bib3gvVGhlc2lzL2FydGljbGVzL0tCUyBSZXBvcnQgQmFjaCBDaG9yYWxlIEhhcm1vbml6YXRpb24ucGRmABMAAS8AABUAAgAR//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AyQDOANYC5gLoAu0C+AMBAw8DEwMaAyMDKAM1AzgDSgNNA1IAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADVA==}}

@article{papadopoulos1999ai,
	Annote = {This paper examines a variety of methods for algorithmic composition. For each method (i.e. systems that learn, grammars, etc.), the major attempts using this methodology are examined, and then the authors provide a list of advantages and disvantages to exploring the approach further. They mention several past approaches taken to the task of harmonization - as a satisfaction constraint problem, as a generative grammar, or as a learn-by-example approach using machine learning.

This paper was written at the turn of the century and therefore lacks some of the more recent research on harmonization using sophisticated neural networks. However, it remains useful as a well-sourced appendix of attempts at automatic harmonization using a variety of computational models. The extensive bibliography will also come in handy for future research.},
	Author = {Papadopoulos, George and Wiggins, Geraint},
	Date-Added = {2015-09-29 18:17:35 +0000},
	Date-Modified = {2015-09-30 05:39:26 +0000},
	Journal = {AISB Symposium on Musical Creativity},
	Keywords = {algorithmic composition},
	Pages = {110--117},
	Publisher = {Edinburgh, UK},
	Title = {AI methods for algorithmic composition: A survey, a critical view and future prospects},
	Year = {1999},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNS4uLy4uL2FydGljbGVzL0FsZ29yaXRobWljIENvbXBvc2l0aW9uIC0gQSBTdXJ2ZXkucGRm0hcLGBlXTlMuZGF0YU8RAgQAAAAAAgQAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM1k0ppIKwAAA013wx9BbGdvcml0aG1pYyBDb21wb3NpIzM0RkExQjkucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADT6G50jBIuAAAAAAAAAAAAAIAAgAACSAAAAAAAAAAAAAAAAAAAAAIYXJ0aWNsZXMAEAAIAADNZQraAAAAEQAIAADSMID4AAAAAQAUA013wwJksJoABfFjAAXEaQACEOkAAgBaTWFjaW50b3NoIEhEOlVzZXJzOgBoemFicmlza2llOgBEcm9wYm94OgBUaGVzaXM6AGFydGljbGVzOgBBbGdvcml0aG1pYyBDb21wb3NpIzM0RkExQjkucGRmAA4ATgAmAEEAbABnAG8AcgBpAHQAaABtAGkAYwAgAEMAbwBtAHAAbwBzAGkAdABpAG8AbgAgAC0AIABBACAAUwB1AHIAdgBlAHkALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAE9Vc2Vycy9oemFicmlza2llL0Ryb3Bib3gvVGhlc2lzL2FydGljbGVzL0FsZ29yaXRobWljIENvbXBvc2l0aW9uIC0gQSBTdXJ2ZXkucGRmAAATAAEvAAAVAAIAEf//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMYAywDTAtsC3QLiAu0C9gMEAwgDDwMYAx0DKgMtAz8DQgNHAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAA0k=}}

@article{chilvers2008chorale,
	Author = {Chilvers, Alex and van Zaanen, Menno},
	Date-Added = {2015-09-29 17:54:31 +0000},
	Date-Modified = {2015-09-29 17:54:55 +0000},
	Journal = {Proceedings of the MML 2008 International Workshop on Machine Learning and Music held in conjunction with ICML/COLT/UAI 2008, Helsinki, Finland},
	Keywords = {chorales, machine learning, neural networks},
	Title = {Chorale Harmonization in the Style of JS Bach A Machine Learning Approach},
	Year = {2008}}

@article{menzel1998structure,
	Author = {H{\"o}rnel, Dominik and Menzel, Wolfram},
	Copyright = {Copyright {\copyright} 1998 The MIT Press},
	Date-Added = {2015-09-29 15:21:26 +0000},
	Date-Modified = {2015-09-29 18:14:32 +0000},
	Issn = {01489267},
	Journal = {Computer Music Journal},
	Jstor_Articletype = {research-article},
	Jstor_Formatteddate = {Winter, 1998},
	Keywords = {neural networks, musical structure},
	Language = {English},
	Number = {4},
	Pages = {pp. 44-62},
	Publisher = {The MIT Press},
	Title = {Learning Musical Structure and Style with Neural Networks},
	Url = {http://www.jstor.org/stable/3680893},
	Volume = {22},
	Year = {1998},
	Bdsk-Url-1 = {http://www.jstor.org/stable/3680893}}

@article{petri1995bebop,
	Abstract = {In cognitive science and research on artificial intelligence, there are two central paradigms: symbolic and analogical. Within the analogical paradigm, artificial neural networks (ANNs) have recently been successfully used to model and simulate cognitive phenomena. One of the most prominent features of ANNs is their ability to learn by example and, to a certain extent, generalize what they have learned. Improvisation, the art of spontaneously creating music while playing or singing, fundamentally has an imitative nature. Regardless of how much one studies and analyzes, the art of improvisation is learned mostly by example. Instead of memorizing explicit rules, the student mimics the playing of other musicians. This kind of learning procedure cannot be easily modeled with rule- based symbolic systems. ANNs, on the other hand, provide an effective means of modeling and simulating this kind of imitative learning. In this article, a model of jazz improvisation that is based on supervised learning ANNs is described. Some results, achieved by simulations with the model, are presented. The simulations show that the model is able to apply the material it has learned in a new context. It can even create new melodic patterns based on the learned patterns. This kind of adaptability is a direct consequence of the fact that the knowledge resides in a distributed form in the network.},
	Annote = {Petri Toivainen presents an artificial neural network (ANN) that given a series of chord changes is able to improvise over them in a jazz bebop style. The target-note technique describes provides signposts at the beginning of each chord change, giving the ANN targets with which to arrive at using a series of melodic patterns. The result is a suprisingly decent melodic improvisation given a small training set - consisting of Clifford Brown's solos on "All the Things You Are" and "Getrude's Bounce".Toivainen's paper is an early example of a computational approach to jazz composition.},
	Author = {Petri Toiviainen},
	Copyright = {Copyright {\copyright} 1995 University of California Press},
	Date-Added = {2015-09-29 15:16:21 +0000},
	Date-Modified = {2015-12-03 07:06:01 +0000},
	Issn = {07307829},
	Journal = {Music Perception: An Interdisciplinary Journal},
	Jstor_Articletype = {research-article},
	Jstor_Formatteddate = {Summer, 1995},
	Keywords = {jazz, bebop, neural networks},
	Language = {English},
	Number = {4},
	Pages = {pp. 399-413},
	Publisher = {University of California Press},
	Title = {Modeling the Target-Note Technique of Bebop-Style Jazz Improvisation: An Artificial Neural Network Approach},
	Url = {http://www.jstor.org/stable/40285674},
	Volume = {12},
	Year = {1995},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QNi4uLy4uL2FydGljbGVzL0JlYm9wIEltcHJvdmlzYXRpb24gTmV1cmFsIE5ldHdvcmtzLnBkZtIXCxgZV05TLmRhdGFPEQIGAAAAAAIGAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADNZNKaSCsAAANNd8MfQmVib3AgSW1wcm92aXNhdGlvbiMzNEZDM0FFLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA0/DrtIwI78AAAAAAAAAAAACAAIAAAkgAAAAAAAAAAAAAAAAAAAACGFydGljbGVzABAACAAAzWUK2gAAABEACAAA0jBb/wAAAAEAFANNd8MCZLCaAAXxYwAFxGkAAhDpAAIAWk1hY2ludG9zaCBIRDpVc2VyczoAaHphYnJpc2tpZToARHJvcGJveDoAVGhlc2lzOgBhcnRpY2xlczoAQmVib3AgSW1wcm92aXNhdGlvbiMzNEZDM0FFLnBkZgAOAFAAJwBCAGUAYgBvAHAAIABJAG0AcAByAG8AdgBpAHMAYQB0AGkAbwBuACAATgBlAHUAcgBhAGwAIABOAGUAdAB3AG8AcgBrAHMALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAFBVc2Vycy9oemFicmlza2llL0Ryb3Bib3gvVGhlc2lzL2FydGljbGVzL0JlYm9wIEltcHJvdmlzYXRpb24gTmV1cmFsIE5ldHdvcmtzLnBkZgATAAEvAAAVAAIAEf//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAMcAzADUAt4C4ALlAvAC+QMHAwsDEgMbAyADLQMwA0IDRQNKAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAA0w=},
	Bdsk-Url-1 = {http://www.jstor.org/stable/40285674}}

@mastersthesis{nagler2014schubot,
	Annote = {Dylan Nagler's undergraduate represents one of the most recent attempts to apply a variety of machine learning models to musical tasks. This demonstrates how the basic questions about automatic harmonization continue to be asked many years later, although the author here applies them to a less common data set - Schubert lieder. He first describes a number of supervised learning methods which might be applied, including hidden Markov models and PCFGs (grammars). He then describes a program he wrote to harmonically analyze Schubert lieder and the metholodogy behind his approach. Nagler is very descriptive in explaining his methodology, which will be additionally useful because of his use of the music21 musicology library to preprocess his data.},
	Author = {Nagler, Dylan Jeremy},
	Date-Added = {2015-09-29 15:11:18 +0000},
	Date-Modified = {2015-09-30 23:56:28 +0000},
	Keywords = {Schubert, chorales, machine learning},
	Month = {March},
	School = {Harvard University},
	Title = {SCHUBOT: Machine Learning Tools for the Automated Analysis of Schubert{\^a}s Lieder},
	Type = {Honors thesis},
	Year = {2014},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QQC4uLy4uLy4uLy4uL0RvY3VtZW50cy9SYW5kb20gRG9jdW1lbnRzL0R5bGFuIE5hZ2xlcidzIFRoZXNpcy5wZGbSFwsYGVdOUy5kYXRhTxEB4AAAAAAB4AACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzWTSmkgrAAAABe+BGUR5bGFuIE5hZ2xlcidzIFRoZXNpcy5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC//tfPYDsRAAAAAAAAAAAABAADAAAJIAAAAAAAAAAAAAAAAAAAABBSYW5kb20gRG9jdW1lbnRzABAACAAAzWUK2gAAABEACAAAz2BzUQAAAAEAEAAF74EABcSpAAXEaQACEOkAAgBWTWFjaW50b3NoIEhEOlVzZXJzOgBoemFicmlza2llOgBEb2N1bWVudHM6AFJhbmRvbSBEb2N1bWVudHM6AER5bGFuIE5hZ2xlcidzIFRoZXNpcy5wZGYADgA0ABkARAB5AGwAYQBuACAATgBhAGcAbABlAHIAJwBzACAAVABoAGUAcwBpAHMALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAEVVc2Vycy9oemFicmlza2llL0RvY3VtZW50cy9SYW5kb20gRG9jdW1lbnRzL0R5bGFuIE5hZ2xlcidzIFRoZXNpcy5wZGYAABMAAS8AABUAAgAR//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4A0QDWAN4CwgLEAskC1ALdAusC7wL2Av8DBAMRAxQDJgMpAy4AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADMA==}}

@mastersthesis{thorpe1998bach,
	Annote = {Unlike many past and future attempts, Chris Thorpe's A.B. thesis explores the task of harmonizing Bach chorales with a bass line rather than a complete set of voices. He uses Markov chains to model the harmonization task, representating a harmony at time T as a given "state" that can transition to any one of a set of other harmonies, in each case with a pre-determined probability of that transition occurring. Thorpe models harmonization in this form as a "completive" rather than generative task, in that the produced bass line is one of a set of valid options.

This paper is one of the most notable Harvard undergraduate theses in Computer Science and Music. Thorpe is forthcoming about his methodology and the reasoning behind it, while also acknowledging the limitations of a Markov-based approach.  

},
	Author = {Christopher A. Thorpe},
	Date-Added = {2015-09-29 15:07:26 +0000},
	Date-Modified = {2015-09-30 14:14:05 +0000},
	Keywords = {chorales, Markov},
	Month = {March},
	School = {Harvard University},
	Title = {C.P.U. Bach : using Markov models for chorale harmonization},
	Type = {Honors thesis},
	Year = {1998},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QIC4uLy4uL1RoZXNpcy1DUFUtQmFjaCBUaG9ycGUucGRm0hcLGBlXTlMuZGF0YU8RAcIAAAAAAcIAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM1k0ppIKwAAAmSwmhpUaGVzaXMtQ1BVLUJhY2ggVGhvcnBlLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACZLBX0T8gAAAAAAAAAAAAAAIAAQAACSAAAAAAAAAAAAAAAAAAAAAGVGhlc2lzABAACAAAzWUK2gAAABEACAAA0T9YQAAAAAEAEAJksJoABfFjAAXEaQACEOkAAgBLTWFjaW50b3NoIEhEOlVzZXJzOgBoemFicmlza2llOgBEcm9wYm94OgBUaGVzaXM6AFRoZXNpcy1DUFUtQmFjaCBUaG9ycGUucGRmAAAOADYAGgBUAGgAZQBzAGkAcwAtAEMAUABVAC0AQgBhAGMAaAAgAFQAaABvAHIAcABlAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA6VXNlcnMvaHphYnJpc2tpZS9Ecm9wYm94L1RoZXNpcy9UaGVzaXMtQ1BVLUJhY2ggVGhvcnBlLnBkZgATAAEvAAAVAAIAEf//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOALEAtgC+AoQChgKLApYCnwKtArECuALBAsYC0wLWAugC6wLwAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAvI=}}

@inproceedings{eck2002blues,
	Annote = {This article is a further development of the ideas Eck proposes in his other 2002 paper (cite-key: eck2002structure), where he demonstrates the ability of LSTMs to develop an understanding of larger musical structures, such as the 12-bar blues form. Here, Eck argues that LSTMs are also highly effective at learning to compose music by analyzing examples of a machine that is able to produce blues melodies. Eck is one of the few researchers to explore the realm of computational harmonic analysis in jazz, and he loves many topics untouched where others could explore.},
	Author = {Eck, Douglas and Schmidhuber, Jurgen},
	Booktitle = {Neural Networks for Signal Processing, 2002. Proceedings of the 2002 12th IEEE Workshop on},
	Date-Added = {2015-09-29 14:35:42 +0000},
	Date-Modified = {2015-10-01 00:01:35 +0000},
	Keywords = {neural networks, RNN, LSTM, jazz},
	Organization = {IEEE},
	Pages = {747--756},
	Title = {Finding temporal structure in music: Blues improvisation with LSTM recurrent networks},
	Year = {2002},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QLC4uLy4uL2FydGljbGVzL0JsdWVzIEltcHJvdmlzYXRpb24gTFNUTXMucGRm0hcLGBlXTlMuZGF0YU8RAeYAAAAAAeYAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM1k0ppIKwAAA013wx1CbHVlcyBJbXByb3Zpc2F0aW9uIExTVE1zLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADTXeu0i+ZcwAAAAAAAAAAAAIAAgAACSAAAAAAAAAAAAAAAAAAAAAIYXJ0aWNsZXMAEAAIAADNZQraAAAAEQAIAADSL9GzAAAAAQAUA013wwJksJoABfFjAAXEaQACEOkAAgBYTWFjaW50b3NoIEhEOlVzZXJzOgBoemFicmlza2llOgBEcm9wYm94OgBUaGVzaXM6AGFydGljbGVzOgBCbHVlcyBJbXByb3Zpc2F0aW9uIExTVE1zLnBkZgAOADwAHQBCAGwAdQBlAHMAIABJAG0AcAByAG8AdgBpAHMAYQB0AGkAbwBuACAATABTAFQATQBzAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBGVXNlcnMvaHphYnJpc2tpZS9Ecm9wYm94L1RoZXNpcy9hcnRpY2xlcy9CbHVlcyBJbXByb3Zpc2F0aW9uIExTVE1zLnBkZgATAAEvAAAVAAIAEf//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAL0AwgDKArQCtgK7AsYCzwLdAuEC6ALxAvYDAwMGAxgDGwMgAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAyI=}}

@misc{karpathy2015rnn,
	Author = {Andrej Karpathy},
	Date-Added = {2015-09-29 14:28:38 +0000},
	Date-Modified = {2015-09-29 14:31:38 +0000},
	Howpublished = {Blog},
	Keywords = {RNN, neural networks},
	Month = {May},
	Title = {The Unreasonable Effectiveness of Recurrent Neural Networks},
	Url = {http://karpathy.github.io/2015/05/21/rnn-effectiveness/},
	Year = {2015},
	Bdsk-Url-1 = {http://karpathy.github.io/2015/05/21/rnn-effectiveness/}}

@inproceedings{hild1992harmonet,
	Author = {Hild, Hermann and Feulner, Johannes and Menzel, Wolfram},
	Booktitle = {Advances in Neural Information Processing Systems},
	Date-Added = {2015-09-29 14:24:20 +0000},
	Date-Modified = {2015-09-29 14:32:54 +0000},
	Keywords = {neural networks, chorales, harmonization},
	Pages = {267--274},
	Title = {HARMONET: A neural net for harmonizing chorales in the style of JS Bach},
	Year = {1992}}

@article{eck2002structure,
	Annote = {Upon examining attempts at automated composition using standard recurrent neural networks (RNNs), the authors Eck and Schmidhuber conclude that these models alone fail to grasp larger musical structures, and therefore are unsuccessful at generating convincing musical compositions. However, a subset of RNNs labeled LSTMs (Long Short-Term Memory) have shown much greater promise due to their ability to retain information about decisions in previous time frames. With respect to music generation, the authors demonstrate its ability to successfully learn a 12-bar blues form and improvise melodies over those harmonies.},
	Author = {Eck, Douglas and Schmidhuber, Juergen},
	Date-Modified = {2015-10-01 00:01:33 +0000},
	Journal = {Istituto Dalle Molle Di Studi Sull Intelligenza Artificiale},
	Keywords = {LSTM, RNN, neural networks, jazz},
	Title = {A first look at music composition using lstm recurrent neural networks},
	Year = {2002}}
